\section{Quadratic Error Function}

Consider a quadratic error function of the form
\[
E = E_0 + \frac{1}{2} (\mathbf{w} - \mathbf{w}^*)^T \mathbf{H} (\mathbf{w} - \mathbf{w}^*)
\]
where \(\mathbf{w}^*\) represents the minimum, and the Hessian matrix \(\mathbf{H}\) is positive definite and constant. Suppose the initial weight vector \(\mathbf{w}(0)\) is chosen to be at the origin and is updated using simple gradient descent
\[
\mathbf{w}^{\tau} = \mathbf{w}^{\tau-1} - \rho \nabla E
\]
where \(\tau\) denotes the step number, and \(\rho\) is the learning rate (which is assumed to be small). Show that, after \(\tau\) steps, the components of the weight vector parallel to the eigenvectors of \(\mathbf{H}\) can be written
\[
w_j^{\tau} = \{1 - (1 - \rho \eta_j)^{\tau} \} w_j^*
\]
where \(w_j = \mathbf{w}^T \mathbf{u}_j\) and \(\mathbf{u}_j\) and \(\eta_j\) are the eigenvectors and eigenvalues, respectively, of \(\mathbf{H}\) so that
\[
\mathbf{H} \mathbf{u}_j = \eta_j \mathbf{u}_j
\]

Show that as \(\tau \to \infty\), this gives \(\mathbf{w}^{\tau} \to \mathbf{w}^*\) as expected, provided \(|1 - \rho \eta_j| < 1\). Now suppose that training is halted after a finite number \(\tau\) of steps. Show that the components of the weight vector parallel to the eigenvectors of the Hessian satisfy
\[
\mathbf{w}_j^{(\tau)} \approx \mathbf{w}_j^* \quad \text{when} \quad \eta_j \gg (\rho \tau)^{-1}
\]
\[
|\mathbf{w}_j^{(\tau)}| \ll |\mathbf{w}_j^*| \quad \text{when} \quad \eta_j \ll (\rho \tau)^{-1}
\]
\begin{qsolve}
    \begin{qsolve}[]
        first we have:
        $$E = E_0 + \frac{1}{2} (\mathbf{w} - \mathbf{w}^*)^T \mathbf{H} (\mathbf{w} - \mathbf{w}^*)$$
        so we can state that:
        $$\nabla E = \mathbf{H} (\mathbf{w} - \mathbf{w}^*)$$
        from the gradient descent formula we have:
        $$\mathbf{w}^{\tau} = \mathbf{w}^{\tau-1} - \rho \nabla E$$
        so we can write:
        $$\mathbf{w}^{\tau} = \mathbf{w}^{\tau-1} - \rho \mathbf{H} (\mathbf{w}^{\tau-1} - \mathbf{w}^*)$$
        since H is symmetric and positive definite, we can write that as:
        $$H = U \Lambda U^T$$
        where U is the matrix of eigenvectors and \(\Lambda\) is the diagonal matrix of eigenvalues. so we can write:
        $$\mathbf{w}^{\tau} = \mathbf{w}^{\tau-1} - \rho U \Lambda U^T (\mathbf{w}^{\tau-1} - \mathbf{w}^*)$$
        \splitqsolve[\splitqsolve]
        $$\Rightarrow \mathbf{w}^{\tau} = U(I-\rho \Lambda)U^T \mathbf{w}^{\tau-1} + \rho U \Lambda U^T \mathbf{w}^*$$
        as we know U is orthogonal, so we can write:
        $$\mathbf{w}^{\tau} = U(I-\rho \Lambda)U^T \mathbf{w}^{\tau-1} + \rho \Lambda \mathbf{w}^*$$
        $$\Rightarrow \mathbf{w}^{\tau}_{j} = \mathbf{w}^{\tau^{T}} \mathbf{u}_j = \mathbf{u}_j^T \mathbf{w}^{\tau} = \mathbf{u}_j^T U(I-\rho \Lambda)U^T \mathbf{w}^{\tau-1} + \rho \mathbf{u}_j^T \Lambda \mathbf{w}^*$$
        $$\Rightarrow \mathbf{w}^{\tau}_{j} = (1-\rho \eta_j) \mathbf{w}^{\tau-1}_{j} + \rho \eta_j \mathbf{w}^*_{j}$$
        for $\tau = 1$ we have:
        $$\mathbf{w}_j^1 = (1-\rho \eta_j) \mathbf{w}_j^0 + \rho \eta_j \mathbf{w}_j^* = \rho \eta_j \mathbf{w}_j^*$$
        for $\tau = 2$ we have:
        $$\mathbf{w}_j^2 = (1-\rho \eta_j) \mathbf{w}_j^1 + \rho \eta_j \mathbf{w}_j^* = (1-\rho \eta_j) \rho \eta_j \mathbf{w}_j^* + \rho \eta_j \mathbf{w}_j^*$$
        so at $\tau$ steps we have:

        \[
        w_j^{\tau} = \rho \eta_j w_j^* + (1 - \rho \eta_j) \rho \eta_j w_j^* + (1 - \rho \eta_j)^2 \rho \eta_j w_j^* + \cdots + (1 - \rho \eta_j)^{\tau-1} \rho \eta_j w_j^*
        \]
        
        if : \( S = a + ar + ar^2 + \cdots + ar^{n-1} \) is given by:
        
        \[
        S = a \frac{1 - r^n}{1 - r}
        \]
        
        \[
        w_j^{\tau} = \rho \eta_j w_j^* \frac{1 - (1 - \rho \eta_j)^{\tau}}{1 - (1 - \rho \eta_j)}
        \]
        so we can write:
        $$ w_j^{\tau} = w_j^* \{1 - (1 - \rho \eta_j)^{\tau} \}$$
        so if $|1 - \rho \eta_j| < 1$ then as $\tau \to \infty$ we have:
        $$w_j^{\tau} \to w_j^*$$
        now we need to show that:
        $$\mathbf{w}_j^{(\tau)} \approx \mathbf{w}_j^* \quad \text{when} \quad \eta_j \gg (\rho \tau)^{-1}$$
        $$|\mathbf{w}_j^{(\tau)}| \ll |\mathbf{w}_j^*| \quad \text{when} \quad \eta_j \ll (\rho \tau)^{-1}$$
        to prove the firs statement we can write:
        as $\eta_j \gg (\rho \tau)^{-1}$ the expression $(1 - \rho \eta_j)^{\tau}$ approches to zero rapidly. so we can write:
        $$w_j^{\tau} = w_j^* (1 - (1 - \rho \eta_j)^{\tau}) \approx w_j^*$$
        now for the second statement we can write:
        when $\eta_j \ll (\rho \tau)^{-1}$ the expression $(1 - \rho \eta_j)^{\tau}$ is close to 1. so we can write:
        $$(1-\rho \eta_j)^{\tau} \approx 1-\rho \eta_j \tau$$
        \splitqsolve[\splitqsolve]
        so we can write:
        $$w_j^{\tau} = w_j^* (1 - (1 - \rho \eta_j)^{\tau}) \approx w_j^* \rho \eta_j \tau$$
        so as $\rho \eta_j \tau \ll 1$ we have:
        $$w_j^{\tau} \ll w_j^*$$

    \end{qsolve}
\end{qsolve}