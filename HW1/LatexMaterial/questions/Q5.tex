\section{Eigenvalues}
Assume \textbf{A} is a $2 \times 2$ matrix with $\lambda_1$ and $\lambda_2$ being its eigenvalues. If $\lambda_1 \neq \lambda_2$, prove:
$$e^A = \dfrac{\lambda_1 e^ {\lambda_2} - \lambda_2 e^{\lambda_1}}{\lambda_1 - \lambda_2}I +\dfrac{e^{\lambda_1} - e^{\lambda_2}}{\lambda_1 - \lambda_2}A$$
\begin{qsolve}
	\begin{qsolve}[]
		first of all we prove the fact that if $\lambda_1 \neq \lambda_2$, then $A$ is diagonalizable. We know that $A$ is diagonalizable if and only if it has $n$ linearly independent eigenvectors. Then we have to prove that if $\lambda_1 \neq \lambda_2$, then $v_1$ and $v_2$ are linearly independent. 
		we assume that:
		$$\alpha v_1 + \beta v_2 = 0$$
		then we have:
		$$\alpha \lambda_1 v_1 + \beta \lambda_1 v_2 = 0\ \ \ (1)$$
		we can also state that:
		$$\alpha  A v_1 + \beta  A v_2 = 0 = \alpha \lambda_1 v_1 + \beta \lambda_2 v_2\ \ \ (2)$$
		by subtracting $(2)$ from $(1)$ we have:
		$$\beta (\lambda_2 - \lambda_1) v_2 = 0$$
		by the fact that $\lambda_1 \neq \lambda_2$, then $\beta = 0$. \textit{The same can be done for $\alpha$}.so we can conclude that $v_1$ and $v_2$ are linearly independent. so $A$ is diagonalizable.
		we can write $A$ as:
		$$A = V \Lambda V^{-1}\ \ \ (3)$$
		where $V$ is the matrix of eigenvectors and $\Lambda$ is the diagonal matrix of eigenvalues. by taylor expansion we have:
		$$e^A = \sum_{i=0}^{\infty} \dfrac{A^i}{i!} = I + A + \dfrac{A^2}{2!} + \dfrac{A^3}{3!} + \cdots\ \ \ (4)$$
		by (3) and some matrix multiplication we have:
		$$A^n = V \Lambda^n V^{-1}$$
		so we can rewrite (4) as:
		$$e^A = I + V \Lambda V^{-1} + \dfrac{V \Lambda^2 V^{-1}}{2!} + \cdots = I + \sum_{i=1}^{\infty} \dfrac{V \Lambda^i V^{-1}}{i!} = V \sum_{i=0}^{\infty} \dfrac{\Lambda^i}{i!} V^{-1} $$
		now we can write $V \dfrac{\Lambda^i}{i!} V^{-1}$ as:
		\splitqsolve[\splitqsolve]
		$$ V \begin{bmatrix}
			\dfrac{\lambda_1^i}{i!} & 0\\
			0 & \dfrac{\lambda_2^i}{i!}
		\end{bmatrix} V^{-1} $$
		we know that:
		$$e^{\lambda_1} = \sum_{i=0}^{\infty} \dfrac{\lambda_1^i}{i!}$$
		$$e^{\lambda_2} = \sum_{i=0}^{\infty} \dfrac{\lambda_2^i}{i!}$$
		so we can write $\sum_{i=0}^{\infty} \dfrac{\Lambda^i}{i!}$ as:
		$$\begin{bmatrix}
			e^{\lambda_1} & 0\\
			0 & e^{\lambda_2}
		\end{bmatrix}$$
		so we can write $e^A$ as:
		$$e^A = V \begin{bmatrix}
			e^{\lambda_1} & 0\\
			0 & e^{\lambda_2}
		\end{bmatrix} V^{-1}\ \ \ (\ast)$$
		now we need to prove that the right hand side of the equation is equal to the left hand side. we write the right hand side as:
		$$\dfrac{V \lambda_1 e^ {\lambda_2} - \lambda_2 e^{\lambda_1}}{\lambda_1 - \lambda_2}I\ V^{-1} +\dfrac{e^{\lambda_1} - e^{\lambda_2}}{\lambda_1 - \lambda_2}V \Lambda V^{-1}$$
		so we have:
		$$V \dfrac{\lambda_1 e^ {\lambda_2} - \lambda_2 e^{\lambda_1}}{\lambda_1 - \lambda_2}I\ V^{-1} + V \begin{bmatrix}
			\dfrac{\lambda_1 e^ {\lambda_1} - \lambda_1 e^{\lambda_2}}{\lambda_1 - \lambda_2} & 0\\
			0 & \dfrac{\lambda_2 e^ {\lambda_1} - \lambda_2 e^{\lambda_2}}{\lambda_1 - \lambda_2}
		\end{bmatrix} V^{-1}$$
		$$ = V \begin{bmatrix}
			\dfrac{\lambda_1 e^ {\lambda_1} - \lambda_2 e^{\lambda_1}}{\lambda_1 - \lambda_2} & 0\\
			0 & \dfrac{\lambda_1 e^ {\lambda_2} - \lambda_2 e^{\lambda_2}}{\lambda_1 - \lambda_2}
		\end{bmatrix} V^{-1} = V \begin{bmatrix}
			e^{\lambda_1} & 0\\
			0 & e^{\lambda_2}
		\end{bmatrix} V^{-1} \ \ \ (\ast \ast) $$
		by $(\ast)$ and $(\ast \ast)$ we can conclude that the right hand side of the equation is equal to the left hand side. so we proved the equation.
	\end{qsolve}
\end{qsolve}
